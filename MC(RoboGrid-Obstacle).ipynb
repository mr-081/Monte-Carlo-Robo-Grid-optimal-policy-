{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4ad7974-bf3c-415a-8380-cc382c1b5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0650b2a1-337c-450d-ae2c-4b8b17f7d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid environment\n",
    "grid_size = 5\n",
    "grid = np.zeros((grid_size, grid_size))  # The grid\n",
    "terminal_states = [(0, 0), (grid_size - 1, grid_size - 1)]  # Terminal states\n",
    "\n",
    "# Define rewards for each state (positive for terminal states)\n",
    "goal_state = (grid_size - 1, grid_size - 1)\n",
    "rewards = np.full((grid_size, grid_size), -1)  # Reward of -1 for each step\n",
    "rewards[0, 0] = 0\n",
    "#rewards[grid_size - 1, grid_size - 1] = 0\n",
    "\n",
    "obstacle = (2, 2)\n",
    "\n",
    "rewards[goal_state] = 10.0  # Positive reward for reaching the goal\n",
    "rewards[obstacle] = -10.0  # Large negative reward for hitting the obstacle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3efc275-7547-498b-abe5-8db80ad8035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define possible movements based on actions\n",
    "actions = {\n",
    "    'up': (-1, 0),\n",
    "    'down': (1, 0),\n",
    "    'left': (0, -1),\n",
    "    'right': (0, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57355cd9-ddea-42ab-848c-866f6afedf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial policy (random actions)\n",
    "policy = {}\n",
    "# Initialize the policy randomly for non-terminal states\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        if (i, j) not in terminal_states and (i, j) != obstacle:  # Avoid terminal and obstacle states\n",
    "            policy[(i, j)] = random.choice(list(actions.keys()))  # Choose a random action\n",
    "# Initialize state-value function arbitrarily\n",
    "state_values = np.zeros((grid_size, grid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "237b4612-1e30-474f-b58c-7eda4890fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the next state after taking an action\n",
    "def get_next_state(state, action):\n",
    "    action_delta = actions[action]  # Convert action string to coordinate change\n",
    "    next_state = (state[0] + action_delta[0], state[1] + action_delta[1])\n",
    "    \n",
    "    # Ensure the next state is within bounds and not an obstacle\n",
    "    if (0 <= next_state[0] < grid_size) and (0 <= next_state[1] < grid_size):\n",
    "        if next_state != obstacle:  # If it's not the obstacle, move\n",
    "            return next_state\n",
    "    \n",
    "    # If next_state is an obstacle or out of bounds, return the current state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56e499e3-7b2e-41b4-9012-63b6ab381033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def monte_carlo_policy_evaluation(episodes, gamma=1.0, max_steps=100):\n",
    "    returns = {}  # Dictionary to store returns for each state\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            returns[(i, j)] = []  # Initialize empty list of returns for each state\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        # Generate an episode\n",
    "        state = (random.randint(0, grid_size - 1), random.randint(0, grid_size - 1))\n",
    "        episode = []\n",
    "        steps = 0\n",
    "        visited_states = set()  # Keep track of visited states\n",
    "        G = 0  # Initialize return\n",
    "        \n",
    "        while state not in terminal_states and state != obstacle and steps < max_steps:\n",
    "            action = policy[state]\n",
    "            next_state = get_next_state(state, action)\n",
    "            reward = rewards[next_state]\n",
    "            \n",
    "            episode.append((state, reward))\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "        \n",
    "        # Compute returns and update state values\n",
    "        for t in range(len(episode)-1, -1, -1):  # Backward pass through the episode\n",
    "            state, reward = episode[t]\n",
    "            G = gamma * G + reward\n",
    "            \n",
    "            # First-visit Monte Carlo\n",
    "            if state not in visited_states:\n",
    "                visited_states.add(state)\n",
    "                returns[state].append(G)\n",
    "                state_values[state] = np.mean(returns[state])  # Update state value with average return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37763b19-a8ca-4e21-87f8-6439f7cf9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Policy Iteration\n",
    "def monte_carlo_policy_iteration(episodes, gamma=1.0):\n",
    "    for _ in range(episodes):\n",
    "        monte_carlo_policy_evaluation(episodes, gamma)\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                state = (i, j)\n",
    "                if state not in terminal_states:\n",
    "                    # Greedy policy improvement based on state values\n",
    "                    action_returns = {}\n",
    "                    for action in actions:\n",
    "                        next_state = get_next_state(state, action)\n",
    "                        action_returns[action] = rewards[next_state] + gamma * state_values[next_state]\n",
    "                    policy[state] = max(action_returns, key=action_returns.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5842b65b-0ef9-4385-9f09-ae74c9773a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Monte Carlo Policy Iteration\n",
    "monte_carlo_policy_iteration(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b509cfac-7624-4b6b-8ef3-e770fad0041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final State Values:\n",
      "[[ 0.  4.  5.  6.  7.]\n",
      " [ 4.  5.  6.  7.  8.]\n",
      " [ 5.  6.  0.  8.  9.]\n",
      " [ 6.  7.  8.  9. 10.]\n",
      " [ 7.  8.  9. 10.  0.]]\n",
      "Final Policy:\n",
      "State (0,0): No policy assigned\n",
      "State (0,1): down\n",
      "State (0,2): down\n",
      "State (0,3): down\n",
      "State (0,4): down\n",
      "State (1,0): down\n",
      "State (1,1): down\n",
      "State (1,2): right\n",
      "State (1,3): down\n",
      "State (1,4): down\n",
      "State (2,0): down\n",
      "State (2,1): down\n",
      "State (2,2): obstacle\n",
      "State (2,3): down\n",
      "State (2,4): down\n",
      "State (3,0): down\n",
      "State (3,1): down\n",
      "State (3,2): down\n",
      "State (3,3): down\n",
      "State (3,4): down\n",
      "State (4,0): right\n",
      "State (4,1): right\n",
      "State (4,2): right\n",
      "State (4,3): right\n",
      "State (4,4): No policy assigned\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print final results\n",
    "print(\"Final State Values:\")\n",
    "print(state_values)\n",
    "print(\"Final Policy:\")\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        if (i, j) != obstacle:  # Skip obstacle\n",
    "            if (i, j) in policy:\n",
    "                print(f\"State ({i},{j}):\", policy[(i, j)])\n",
    "            else:\n",
    "                print(f\"State ({i},{j}): No policy assigned\")\n",
    "        else:\n",
    "            print(f\"State ({i},{j}): obstacle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727874d-5612-4f75-abde-007a1e29654b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
